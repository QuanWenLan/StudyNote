### 数据库

##### 说说事务的概念

ACID

##### 说说preparedStatement和statement的区别

- 效率：预编译PreparedStatement会比普通会话对象效率高，数据库不会对相同的sql语句再次编译。

- 安全性：可以有效地避免**sql注入攻击**，sql注入攻击就是从客户端驶入一些非法的特殊字符，而使服务器端在构造sql语句的时候仍然能够正确构造，从而收集程序和服务器的信息和数据。

  实例：比如“select * from t_user where username=' ” + username+"' and password = ' " + " ' ";

  账号是1密码输入 1 or 1 = 1，这个语句中的where部分没有起到筛选数据的作用。

##### SQL查询出来的结果分页展示一般怎么做？

Oracle：

```mysql
select * from 
	(select *,rownum as num from table where num < pageSize*pageNumber) t where t.num > pageSize*(pageNumber-1);
-- 或者
select * from 
(select *,rownum as tempid from student )  t 
where t.tempid between ” + pageSize*(pageNumber-1) + ” and ” +pageSize*pageNumber;
```

Mysql:

```mysql
 select * from students limit ” + pageSize*(pageNumber-1) + “,” + pageSize;
```

##### JDBC的ResultSet是什么？

在查询数据库后会返回一个ResultSet，它就像是**查询结果集的一张数据表**。
**ResultSet对象维护了一个游标**，指向当前的数据行。开始的时候这个游标指向的是第一行。如果调用了ResultSet的next()方法游标会下移一行，如果没有更多的数据了，next()方法会返回false。可以在for循环中用它来遍历数据集。
默认的ResultSet是不能更新的，游标也只能往下移。也就是说你只能从第一行到最后一行遍历一遍。不过也可以创建可以回滚或者可更新的ResultSet。

#### MySQL

##### MySQL索引的结构、如何创建索引、创建索引遵循的原则

##### SQL优化

##### 两千万数据 B+ 树高度是多少？

##### index 索引为啥查询很快

> B+ 树的查询效率，log n，相比全表扫描当然很快。

##### MySQL的几种日志（redo、undo、binlog）的区别和作用、explain 的字段的理解

##### MySQL的explain解读

##### MySQL同一个SQL语句在2个时间段执行计划会不同吗？

可能，会因为数据量而优化器选择索引不一样

##### 超大分页和深度分页如何处理

这是由于 MySQL 并不是跳过 offset 的行数，而是取 offset + limit 行，然后丢弃前 offset 行，返回 limit 行，当offset特别大的时候，效率就非常的低下。

```mysql
##查询语句
select id from product limit 10000000, 10
##优化方式一
SELECT * FROM product WHERE ID > =(select id from product limit 10000000, 1) limit 10
##优化方式二
SELECT * FROM product a JOIN (select id from product limit 10000000, 10) b ON a.ID = b.id
```

[覆盖索引，延迟关联](https://www.cnblogs.com/wang-meng/p/ae6d1c4a7b553e9a5c8f46b67fb3e3aa.html)

##### count(*) 走索引吗？

https://blog.csdn.net/LJFPHP/article/details/105255694

**1 结论**

（1）索引长度最小的字段会优先被count(*)选择，一般是int类型的
（2）如果索引长度一致，那么选择基数最小的（这部分是猜测，但是综合各种文章，感觉还是有可信度的）
（3）如果索引基数一致，选择索引长度最小的
（4）大表的count()查询优化手段就是新增tinyint类型的标识字段，速度可以得到有效提升

**2 其他**

（1）**这些sql都是建立在没有where条件的基础上**。

如果有where条件，那么就会使用where条件中的索引，这样的话，count查询的速度是不能保证的。目前没什么好办法，除非你的where条件用到的索引刚好符合咱们上面说的，基数小，索引长度小。

（2）**如果只是要手动统计一个达标有多少条数据，可以采用另一种方式**

```mysql
SELECT TABLE_ROWS FROM `information_schema`.tables WHERE table_name='xxx'
```

缺点：不够实时，这个类似于定时统计表条数写入的关系，如果对数据要求不是很精准的话，可以用这个。



---

#### hibernate

##### 在hibernate进行多表查询每个表中各取几个字段，也就是说查询出来的结果集没有一个实体类与之对应如何解决？

- 按照Object[]数组取出数据，对应组装成一个bean。
- 对每个表所对应的bean，有那个field就定义多少个构造函数。

##### 介绍下hibernate的二级缓存。

回答思路：1. 什么hibernate的缓存？2. hibernate的session就是一级缓存，为什么有了一级缓存还要有二级缓存？3. 如何配置hibernate的二级缓存。

- 1，缓存就是把以前从数据库中查询出来和使用过的对象保存在内存中（一个数据结构中），这个数据结构通常是或类似HashMap，当以后要使用某个对象时，先查询缓存中是否有这个对象，如果有则使用缓存中的对象，如果没有则去查询数据库，并将查询出来的对象保存在缓存中，以便下次使用。
- 2，**Hibernate的Session就是一种缓存，我们通常将之称为Hibernate的一级缓存**，当想使用session从数据库中查询出一个对象时，Session也是先从自己内部查看是否存在这个对象，存在则直接返回，不存在才去访问数据库，并将查询的结果保存在自己内部。
- **注意**：**Session代表一次会话过程，一个Session与一个数据库连接相关，所以Session最好不要长时间打开，通常仅用于一个事务当中，在事务结束时就应该关闭。并且Session是线程不安全的，当多个线程共享一个session时容易出现问题。**通常只有那种全局意义上的缓存才是真正的缓存应用，才有较大的缓存价值，因此，Hibernate的Session这一级缓存的缓存作用并不明显，应用价值不大。**Hibernate的二级缓存就是要为Hibernate配置一种全局缓存，让多个线程和多个事务都可以共享这个缓存。**我们希望的是一个人使用过，其他人也可以使用，session没有这种效果。
- 二级缓存是独立于Hibernate的软件部件，属于第三方的产品，多个厂商和组织都提供有缓存产品，例如，EHCache和OSCache等等。在Hibernate中使用二级缓存，**首先就要在hibernate.cfg.xml配置文件中配置使用哪个厂家的缓存产品**，接着**需要配置该缓存产品自己的配置文件**，最后**要配置Hibernate中的哪些实体对象要纳入到二级缓存的管理中。**

##### hibernate的三种状态转换

Hibernate Pojo的三态分别为transient（瞬时态）,persistent（持久态）,detached（游离态）

1. 官方给出的三态与Session的关系如下：

**transient:** never persistent, not associated with any Session
**persistent:** associated with a unique Session
**detached:** previously persistent, not associated with any Session

2. 三种状态间相互转换关系，及他们在数据库、session中的状态如下：

a.当我们new一个pojo时，它处于瞬时态，此时与session、数据库均无任何关联。

b.此后，我们获得session并开启hibernate事务，调用save(),persist(),saveOrUpdate()方法，将pojo转变为持久态，此时session中存有这个pojo，但直到transaction.commit()被调用时，sql语句才会执行，此后数据库中也才有此条数据。

c.但当commit()并且session.close()执行过后，pojo就变为了游离态，也就是说，数据库中有该记录，但session中不再有。

d.持久化状态的实例，也可以重新变成瞬时态，那就是调用delete()方法。

e.通过get()或load()方法得到的pojo是持久态的。

f.游离态的pojo可以通过update(),saveOrUpdate(),lock()和replicate()方法重新成为持久态。

g.调用merge()方法后，pojo维持原态，但内容会被更新到数据库。

#### Redis

##### redis双写如何保持数据一致性，哨兵集群和切片集群的区别

##### redis如何处理bigkey，有什么问题

问题：

1. 使用Redis自带的`--bigkeys`参数来查找
2. 分析RDB文件

##### redis内存碎片

1. **Redis 存储存储数据的时候向操作系统申请的内存空间可能会大于数据实际需要的存储空间。**

   每次分配的内存空间都是以最近字节数的2的倍数来分配的。

2. 频繁修改数据，导致空间前后不一致。

直接通过 `config set` 命令将 `activedefrag` 配置项设置为 `yes` 即可。

##### redis并发访问

原子操作：

1. **把多个操作在 Redis 中实现成一个操作，也就是单命令操作**；
2. **把多个操作写到一个 Lua 脚本中，以原子性方式执行单个 Lua 脚本**。 

##### redis实现分布式锁

###### 单个节点

使用一个变量用来判断是否加锁成功，如 lock_key，加锁成功为1，释放为0，

使用 `SETNX` 实现加锁操作。存在则不设置，不存在则创建。使用 `DEL`实现释放锁操作。类似于：

```java
// 加锁
SETNX lock_key 1
// 业务逻辑
DO THINGS
// 释放锁
DEL lock_key
```

（1）在使用`setnx`后，操作共享数据时发生异常，没有执行到 `del` 命令，导致一直被该客户端持有，其他客户端获取不到锁。解决：给锁变量设置一个过期时间，过期后，删除。

（2）**如果客户端 A 执行了 SETNX 命令加锁后，假设客户端 B 执行了DEL 命令释放锁，此时，客户端 A 的锁就被误释放了**。如果客户端 C 正好也在申请加锁，就可以成功获得锁，进而开始操作共享数据。这样一来，客户端 A 和 C 同时在对共享数据进行操作，数据就会被修改错误。解决：针对这种让**每个客户端给所变量设置一个唯一值，这个可以用来标识客户端，释放锁时，判断是不是和这个值相等，相等才释放（可使用lua脚本完成多个命令）**。

###### 多个节点的分布式锁

使用 RedLock 算法。

**Redlock 算法的基本思路，是让客户端和多个独立的 Redis 实例依次请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁了，否则加锁失败**。这样一来，**即使有单个 Redis 实例发生故障，因为锁变量在其它实例上也有保存，所以，客户端仍然可以正常地进行锁操作，锁变量并不会丢失**。  

第一步：客户端获取当前时间

第二步：客户端按顺序依次向 N 个 Redis 实例执行加锁操作 

这里的加锁操作和在单实例上执行的加锁操作一样，使用 SET 命令，带上 NX，EX/PX 选项，以及带上客户端的唯一标识。当然，**如果某个 Redis 实例发生故障了，为了保证在这种情况下，Redlock 算法能够继续运行，我们需要给加锁操作设置一个超时时间**。

**如果客户端在和一个 Redis 实例请求加锁时，一直到超时都没有成功，那么此时，客户端会和下一个 Redis 实例继续请求加锁**。**加锁操作的超时时间需要远远地小于锁的有效时间，一般也就是设置为几十毫秒**。

第三步：一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时。

客户端只有在满足下面的这两个条件时，才能认为是加锁成功 ：

- 条件一：**客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁**；  
- 条件二：**客户端获取锁的总耗时没有超过锁的有效时间**。  

在满足了这两个条件后，我们**需要重新计算这把锁的有效时间，计算的结果是锁的最初有效时间减去客户端为获取锁的总耗时**。**如果锁的有效时间已经来不及完成共享数据的操作了，我们可以释放锁，以免出现还没完成数据操作，锁就过期了的情况**。

###### redission 实现自动续期锁的过期时间

Redisson 中的分布式锁自带自动续期机制，使用起来非常简单，原理也比较简单，其提供了一个专门用来监控和续期锁的 **Watch Dog（ 看门狗）**，如果操作共享资源的线程还未执行完成的话，Watch Dog 会不断地延长锁的过期时间，进而保证锁不会因为超时而被释放。

默认情况下，每过 10 秒，看门狗就会执行续期操作，将锁的超时时间设置为 30 秒。看门狗续期前也会先判断是否需要执行续期操作，需要才会执行续期，否则取消续期操作。

------

著作权归所有 原文链接：https://javaguide.cn/distributed-system/distributed-lock.html



##### redis实现事务ACID

###### 原子性

命令入队时就报错，会放弃事务执行，保证原子性；

命令入队时没报错，实际执行时报错，不保证原子性；

EXEC 命令执行时实例故障，如果开启了 AOF 日志，可以保证原子性。

###### 一致性

命令入队时就报错：**事务本身就会被放弃执行，所以可以保证数据库的一致性**。

命令入队时没报错，实际执行时报错 ：**有错误的命令不会被执行，正确的命令可以正常执行，也不会改变数据库的一致性**。

EXEC 命令执行时实例故障：

- 没开启RDB或AOF，实例故障重启后，数据都没有了，数据库是一致的。
- 使用了RDB，因为 RDB 快照不会在事务执行时执行，所以，事务命令操作的结果不会被保存到 RDB 快照中，使用 RDB 快照进行恢复时，数据库里的数据也是一致的。
- 使用了AOF，而事务操作还没有被记录到 AOF 日志时，实例就发生了故障，那么，使用 AOF 日志恢复的数据库数据是一致的；如果只有部分操作被记录到了AOF 日志，我们可以使用 redis-check-aof 清除事务中已经完成的操作，数据库恢复后也是一致的。

###### 隔离性

1.  **并发操作在 EXEC 命令前执行，此时，隔离性的保证要使用 WATCH 机制来实现，否则隔离性无法保证**； 
2.  **并发操作在 EXEC 命令后执行，此时，隔离性可以保证**。

###### 持久性

因为AOF和RDB都存在丢失数据的风险，所以不能保证持久性。

##### redis持久化策略，AOF和RDB

AOF日志重写的时候，有一处拷贝，两处日志。

RDB则是在某一时刻将数据保存为二进制数据，此时复制是阻塞的。

##### 使用redis实现延迟任务

https://blog.csdn.net/weixin_38399962/article/details/101511408

##### redis只读缓存、读写缓存（数据不一致问题）

**只读缓存**：**当 Redis 用作只读缓存时，应用要读取数据的话，会先调用 Redis GET 接口，查询数据是否存在**。而**所有的数据写请求，会直接发往后端的数据库，在数据库中增删改**。**对于删改的数据来说，如果 Redis 已经缓存了相应的数据，应用需要把这些缓存的数据删除，Redis 中就没有这些数据了**。

好处是：**所有最新的数据都在数据库，数据库提供了持久性的保障**。

问题1：**数据库、缓存一方失败时**

当数据库删改数据出现异常，缓存中已经删除了是最新数据，数据库是旧数据，再读取则读到的是数据库的旧数据；当删改数据库正常，缓存删除异常，则缓存是旧数据，数据库是新数据。

解决

> **可以把要删除的缓存值或者是要更新的数据库值暂存到消息队列中**（例如使用 Kafka 消息队列）。**当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新**。
>
> **如果能够成功地删除或更新，我们就要把这些值从消息队列中去除，以免重复操作，此时，我们也可以保证数据库和缓存的数据一致了**。**否则的话，我们还需要再次进行重试**。**如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了**。

问题2：**删除缓存、更新数据库时有大量并发读操作**

1：先删缓存，再更新数据库。线程A删除缓存，还没更新数据库，线程B开始读取数据，线程B发现缓存缺失，然后去数据库读取数据，读到旧值，然后将读取到的旧值更新到缓存，这时缓存中的数据就是旧值了，发生数据不一致。此时A再更新数据库。

解决：**延迟双删**。在A更新数据库后，sleep一小段时间，再执行一次删除缓存的操作。**线程 A sleep 的时间，就需要大于线程 B 读取数据再写入缓存的时间**。

2：先更新数据库，在删除缓存。**如果线程 A 删除了数据库中的值，但还没来得及删除缓存值，线程 B 就开始读取数据了，那么此时，线程 B 查询缓存时，发现缓存命中，就会直接从缓存中读取旧值**。

总结：

![image-20220531171302985](media/images/image-20220531171302985.png)

**读写缓存**：**除了读请求会发送到缓存进行处理（直接在缓存中查询数据是否存在)，所有的写请求也会发送到缓存，在缓存中直接对数据进行增删改操作**。

不同之处在于，**最新的数据在redis中**。有两种写回策略：

- 同步直写

  写请求发给缓存的同时，也会发给后端数据库进行处理，等到缓存和数据库都写完数据，才给客户端返回。但是同步直写会降低缓存的访问性能。**当有数据一致性问题时，一般选择同步直写策略**。

- 异步写回

  **所有写请求都优先在缓存中处理**。**等到这些增改的数据要被冲缓存中淘汰出来时，缓存将他们写会后端数据库**。这样一来，处理这些数据的操作是在缓存中进行的，很快就能完成。只不过，**如果发生了掉电，而它们还没有被写回数据库，就会有丢失的风险了**。

选择：

- 如果需要对写请求进行加速，我们选择读写缓存；
- 如果写请求很少，或者是只需要提升读请求的响应速度的话，我们选择只读缓存

##### 过期策略

###### 定期删除和惰性删除

定期删除，指的是redis默认是每隔100ms就**随机抽取一些**设置了过期时间的key，检查是否过期，如果过期就删除。

假设redis里放了10W个key，都设置了过期时间，你每隔几百毫秒就检查全部的key，那redis很有可能就挂了，CPU负载会很高，都消耗在检查过期的key上。注意，这里不是每隔100ms就遍历所有设置过期时间的key，那样就是一场性能灾难。实际上redis是每隔100ms就**随机抽取**一些key来检查和删除的。

 定期删除可能会导致很多过期的key到了时间并没有被删除掉。这个时候就可以用到惰性删除了。惰性删除是指在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间并且已经过期了，此时就会删除，不会给你返回任何东西。

但即使是这样，依旧有问题。如果定期删除漏掉了很多过期的key，然后你也没及时去查，也就没走惰性删除。此时依旧有可能大量过期的key堆积在内存里，导致内存耗尽。

这个时候就需要**内存淘汰机制**了。

##### 缓存替换策略（淘汰机制）

**默认情况下，redis不会淘汰数据**。

不进行淘汰的策略：**neoviction**

**设置了过期时间**的淘汰策略：

- **volatile-ttl 在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除**。
- **volatile-random 就像它的名称一样，在设置了过期时间的键值对中，进行随机删除**。
- **volatile-lru 会使用 LRU 算法筛选设置了过期时间的键值对**。**LRU(Least Recently Used 最近最少使用)**
- **volatile-lfu 会使用 LFU 算法选择设置了过期时间的键值对**。**LFU(Least Frequently Used 最不经常使用)**

**在所有数据范围时间**的淘汰策略：

- **allkeys-random 策略，从所有键值对中随机选择并删除数据**；
- **allkeys-lru 策略，使用 LRU 算法在所有数据中进行筛选**。
- **allkeys-lfu 策略，使用 LFU 算法在所有数据中进行筛选**。

##### 缓存雪崩

**缓存雪崩是指大量的应用请求无法在 Redis 缓存中进行处理，紧接着，应用将大量请求发送到数据库层，导致数据库层的压力激增**。

原因：

1 **缓存中有大量数据同时过期，导致大量请求无法得到处理**。

解决方案：

- **微调过期时间**

  **我们可以避免给大量的数据设置相同的过期时间，如果业务层的确要求有些数据同时失效，你可以在用 EXPIRE 命令给每个数据设置过期时间时，给这些数据的过期时间增加一个较小的随机数**。

- **服务降级，是指发生缓存雪崩时，针对不同的数据采取不同的处理方式**

  - **当业务应用访问的是非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息**；
  - **当业务应用访问的是核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取**。

2 **Redis 示例发生故障宕机**

解决方案：

- 在业务系统中实现服务熔断或请求限流机制
  - **服务熔断：是指在发生缓存雪崩时，为了防止引发连锁的数据库雪崩，甚至是整个系统的崩溃，我们暂停业务应用对缓存系统的接口访问**
  - **请求限流：在业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库**

- 事前预防，搭建缓存高可靠集群
- 一致性hash环的集群特性导致

##### 缓存击穿

**缓存击穿是指，针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。缓存击穿的情况，经常发生在热点数据过期失效时**。

解决方案

**对热点数据不设置过期时间**

##### 缓存穿透

**缓存穿透是指要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据**

原因：

- **业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据**；
- **恶意攻击：专门访问数据库中没有的数据**。

解决方案

1. **返回默认的空值或者缺省值**。
2. **使用布隆过滤器，判断数据是否存在**。有可能会误判，因为hash函数计算的位置有可能会是同一个。

3. **在请求入口的前端进行请求检测**。**缓存穿透的一个原因是有大量的恶意请求访问不存在的数据**，所以，一个有效的应对方案是在请求入口前端，**对业务系统接收到的请求进行合法性检测，把恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉**，不让它们访问后端缓存和数据库

##### redis和memcached，如何选择？

###### 功能和持久化

reis的功能更强大，支持5中数据结构，string、list、hash、set、zset。支持AOF和RDB的持久化方式。事务、LUA、MQ、时间序列的功能。

memcached kv的简单存储，不支持持久化。拓展性差，没有redis功能丰富。

###### 内存管理

redis：过期和内存淘汰策略。适合做数据存储。

memcached：预分配池的管理，内存 slab 块，根据增长因子

###### IO

redis：IO多路复用，命令还是单线程的。单线程。

memcached：非阻塞的IO，并且是多路复用。多线程

